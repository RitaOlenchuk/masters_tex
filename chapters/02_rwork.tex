\chapter{Related work}
The focus of the following chapter is the most critical areas of computer vision: deep learning-based approaches for semantic image segmentation, particularly for medical images analysis. As Shephard, Adam et al. discuss~\cite{shephard2022tiager} segmentation of tumor/stroma as well as the detection of TILs can be viewed as semantic segmentation problem. 
\section{Deep learning-based semantic segmentation}
Semantic segmentation is a computer vision task that aims to differentiate regions by assigning a class label to each pixel. Due to the success of deep learning models in a wide range of vision applications, various deep learning-based algorithms for image segmentation have been developed and published in the literature~\cite{minaee2021image}. One of the most prominent deep learning architectures used by the computer vision community include fully convolutional networks (FCNs)~\cite{long2015fully}, encoder-decoders~\cite{noh2015learning}, generative adversarial networks (GANs)~\cite{goodfellow2014generative} and recurrent neural networks (RNNs)~\cite{rumelhart1986learning}.

FCNs~\cite{long2015fully} are among the most widely used architectures for computer vision tasks and their general architecture consists of several learnable convolutions, pooling layers, and a final 1$\times$1 convolution. While models based on this architecture perform well on challenging segmentation benchmarks, e.g. applied on scene segmentation~\cite{yu2020context} and instance aware semantic segmentation~\cite{li2017fully}, they are also used on segmentation problems in histology domain such as colon glands segmentation~\cite{bentaieb2016topology}, identification of muscle and messy regions in contexts of inflammatory bowel disease~\cite{wang2016deep} as well as nuclei~\cite{natarajan2020segmentation} and TILs~\cite{amgad2019joint} segmentation for breast cancer all performed on the Hematoxylin and Eosin (H\&E) stained histopathology images. Moreover, the FCN method was applied for semantic segmentation of TCGA~\cite{gutman2013cancer} breast data set~\cite{amgad2019structured}, which is also used in this master thesis. However, despite its popularity, the conventional FCN model has limitations such as loss of localization and the inability to process potentially useful global context information due to a series of down-sampling and a high sampling rate.

A popular group of deep learning models for semantic image segmentation that aims to solve the aforementioned issues of FCNs is based on the convolutional encoder-decoder architecture~\cite{noh2015learning}. Their model consists of two parts, an encoder consisting of convolutional layers and a deconvolution network that consists of deconvolution and unpooling layers that take the feature vector as input and generate a map of pixel-wise class probabilities. Example for such a convolutional encoder-decoder architecture for image segmentation is SegNet~\cite{badrinarayanan2017segnet}. The SegNet's encoder network has 13 convolutional layers with corresponding layers in the decoder. The final decoder output is fed to a multi-class soft-max classifier to produce class probabilities for each pixel independently. The main feature of SegNet is that the decoder uses pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling. This allows it to achieve high scores for road scene understanding problems~\cite{badrinarayanan2017segnet}, COVID-19 lung computed tomography image segmentation~\cite{saood2021covid}, liver tumor segmentation in computed tomography scans~\cite{almotairi2020liver} and colon cancer histopathological images analysis~\cite{hamida2021deep}. There are several encoder-decoder models initially developed for biomedical image segmentation. Ronneberger et al.~\cite{10.1007/978-3-319-24574-4_28} proposed the U-Net model for segmenting biological microscopy images that can train with few annotated images effectively. U-Net has an FCN-like down-sampling part that extracts features with 3$\times$3 convolutions and an up-sampling part. Feature maps from the encoder are copied to the corresponding decoder part of the network to avoid losing pattern information. Besides the segmentation of neuronal structures in electron microscopic recordings demonstrated in the original paper~\cite{10.1007/978-3-319-24574-4_28}, U-Net was applied for numerous further tasks such as nuclei segmentation in histology images~\cite{lagree2021review, zeng2019ric}, segmenting individual colon glands in histopathology images~\cite{pinckaers2019neural}, epidermal tissue segmentation in histopathological images of skin biolsies~\cite{oskal2019u} and cell segmentation on histopathology triple-negative breast cancer patients dataset~\cite{bagdigen2020cell}. A further example of an encoder-decoder model for semantic segmentation of histopathology images is HookNet~\cite{van2021hooknet}. The architecture consists of two encoder-decoder branches to extract contextual and fine-grained detailed information and combine it (hook up) for the target segmentation. The model showed improvement compared with single-resolution models and was applied to segment different histopathologies like breast cancer tissue sections~\cite{van2021hooknet}, lung squamous cell carcinoma~\cite{van2021hooknet}, invasive melanoma tumor~\cite{shahdeep} and cervical cancer~\cite{meng2021cervical} slides.

Another widely used group of deep learning models for semantic segmentation are the atrous (or dilated) convolutional models that include the DeepLab family~\cite{chen2017deeplab, chen2017rethinking}. The use of atrous convolutions addresses the decreasing resolution caused by max-pooling and striding and Atrous Spatial Pyramid Pooling (ASPP) analyzes an incoming convolutional feature layer with filters at multiple sampling rates allowing to capture objects and image context at multiple scales to robustly segment objects at multiple scales. DeepLabv3+~\cite{chen2018encoder} uses encoder-decoder architecture including atrous separable convolution, composed of a depthwise convolution (spatial convolution for each channel of the input) and pointwise convolution (1$\times$1 convolution with the depthwise convolution as input). Authors~\cite{chen2018encoder} demonstrated the effectiveness of DeppLabv3+ model with modified Xception backbone at recognition of visual object classes in realistic scenes, but it also found multiple applications such as skin lesion segmentation~\cite{azad2020attention}, segmentation of H\&E stained breast cancer~\cite{priego2020automatic} and colorectal carcinoma~\cite{xu2022spatial} histopathology images. Despite all the efforts, even this popular architecture has constraints in learning long-range dependency and spatial correlations due to the inductive bias of locality and weight sharing~\cite{xie2021cotr} that may result in sub-optimal segmentation of complex structures. 

GANs~\cite{goodfellow2014generative} have been applied to a wide range of computer vision tasks, and have been adopted for image segmentation too. The general architecture of GANs consists of the discriminator and the generator. The generator learns the training data distribution and produces similar data, while the discriminator discriminates between real data and simulated data. Hence the task of the generator is to learn to generate the best images to fool the discriminator. There are many extended models such as conditional GAN (cGAN)~\cite{mirza2014conditional} where the additional information is added to both the generator and the discriminator as a condition. This architecture was used for semantic segmentation of brain tumor in magnetic resonance imaging~\cite{rezaei2017conditional} and nuclei segmentation in histopathology images~\cite{mahmood2019deep}. Further extended version of cGAN, pix2pix~\cite{isola2017image} was developed for conversion between different types of images but also found use cases in medical setting such as cell image segmentation on the fluorescence liver images~\cite{Tsuda_2019_CVPR_Workshops} and retinal blood vessel segmentation~\cite{popescu2021retinal}. A further GAN extension originally developed for image transformation between two domains but also applicable for segmentation is CycleGAN~\cite{zhu2017unpaired}. The architecture has two mirror-symmetric GANs to form a ring network to find the mapping between domains. For instance, CycleGAN was applied to kidney tissue ~\cite{gadermayr2019generative} segmentation. Some GAN-based models were specifically developed for semantic segmentation in the medical domain, such as Domain Adaptation and Segmentation GAN (DASGAN)~\cite{kapil2019dasgan} that performs image-to-image translation and semantic tumor epithelium segmentation. It has an extended CycleGAN architecture with discriminator networks adjusted to predict pixel-wise class probability maps on top of predicting the correct source of an image. As a further example the proposed architecture consisting of pyramid of GAN structures~\cite{li2022high}, each responsible for generating and segmenting images at a different scale, was applied to segment prostate histopathology images.

RNNs~\cite{rumelhart1986learning} have also proven to be useful in modeling the short/long-term dependencies among pixels to generate segmentation maps. Pixels can be linked together and processed sequentially to model global contexts and improve semantic segmentation. ReSeg~\cite{visin2016reseg} is an RNN-based model for semantic segmentation. Each layer is composed of four RNNs that go through the image horizontally and vertically in both directions to provide relevant global information, while convolutional layers extract local features that are then followed by up-sampling layers to recover the predictions at original image resolution. Another important development is a pixel-level segmentation of scene images using a long-short-term-memory (LSTM) network~\cite{byeon2015scene}. Segmentation is then carried out by 2D LSTM networks, allowing texture and spatial model parameters to be learned within a single model. But despite all further developments that showcase the potential even for histopathology image segmentation: RACE-net~\cite{chakravarty2018race} applied for segmentation of the cell nuclei in H\&E stained breast cancer slides, Her2Net~\cite{saha2018her2net} segmenting cell membranes and nuclei from human epidermal growth factor receptor-2 (HER2)-stained breast cancer images, etc., 
an important limitation of RNNs is that, due to their sequential nature, they are comparably slower, since this sequential calculation cannot be easily parallelized. 

The Transformer in  Natural Language Processing is an architecture that aims to solve sequence-to-sequence problems based on encoder-decoder architecture. These models rely on self-attention mechanisms and capture long-range dependencies among tokens (words) in a sentence without using RNNs or convolution. Transformers have also emerged into image semantic segmentation. Recent studies have shown that the Transformers can achieve superior performance than CNN-based approaches in various semantic segmentation applications~\cite{nguyen2022evaluating}. The state-of-the-art Transformer-based semantic segmentation methods can be often applied either as convolution-free models or/and as CNN-Transformer hybrid models. Swin-Transformer~\cite{liu2021swin} for instance is a pure hierarchical Transformer that can serve as a  backbone for various computer vision tasks including semantic segmentation. To tokenize the image, it brakes the image into windows that further consist of patches. It constructs a hierarchical representation of an image by starting from small-sized patches and gradually merging neighboring patches into deeper Transformer layers. Swin-Transformer or its slightly modified successors found its application in the medical domain as well, often as a backbone, for example for colon cancer segmentation in H\&E stained histopathology images~\cite{qian2022transformer} or gland segmentation~\cite{lin2022ds}. A further popular fully transformer-based model for semantic segmentation is Segmenter~\cite{strudel2021segmenter}. The encoder consists of Multi-head Self Attention and Multi-Layer Perceptron (MLP) blocks, as well as two-layer norms and residual connections after each block and a linear decoder that bilinearly up-samples the sequence into a 2D segmentation mask. While performing well on scene segmentation~\cite{strudel2021segmenter}, is not particularly used in the medical domain. In the field of medical image segmentation, TransUNet~\cite{chen2021transunet} was the first attempt to establish self-attention mechanisms by combining transformer with U-Net and proved that transformers can be used as powerful encoders for medical image segmentation. A novel positional-encoding-free Transformer SegFormer~\cite{https://doi.org/10.48550/arxiv.2105.15203} set new state-of-the-art in terms of efficiency and accuracy in publicly available semantic segmentation datasets and applied for instance in gland and nuclei segmentation~\cite{lin2022ds}. This architecture remains promising also for semantic segmentation in medical applications due to positional-encoding-free encoder and lightweight MLP decoder.
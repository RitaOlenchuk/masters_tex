\chapter{Related work}
\section{Deep learning-based semantic segmentation}
The focus of the following chapter is the deep learning-based approaches for semantic image segmentation, particularly for medical images analysis. As Shephard, Adam et al. discuss~\cite{shephard2022tiager} segmentation of tumor/stroma as well as the detection of TILs can be viewed as semantic segmentation problem. 

The goal of semantic segmentation is to assign each image pixel to a category label corresponding to the underlying object. Due to the success of deep learning models in a wide range of vision applications, various deep learning-based algorithms have been developed and published in the literature~\cite{minaee2021image}. One of the most prominent deep learning architectures used by the computer vision community include fully convolutional networks (FCNs)~\cite{long2015fully}, encoder-decoders~\cite{noh2015learning}, generative adversarial networks (GANs)~\cite{goodfellow2014generative} and recurrent neural networks (RNNs)~\cite{rumelhart1986learning}.

\subsection{Fully convolutional networks (FCNs)}
FCNs~\cite{long2015fully} are among the most widely used architectures for computer vision tasks and their general architecture consists of several learnable convolutions, pooling layers, and a final 1$\times$1 convolution. While models based on this architecture perform well on challenging segmentation benchmarks, e.g. applied on scene segmentation~\cite{yu2020context} and instance aware semantic segmentation~\cite{li2017fully}, they are also used on segmentation problems in histology domain such as colon glands segmentation~\cite{bentaieb2016topology}, identification of muscle and messy regions in contexts of inflammatory bowel disease~\cite{wang2016deep} as well as nuclei~\cite{natarajan2020segmentation} and TILs~\cite{amgad2019joint} segmentation for breast cancer all performed on the Hematoxylin and Eosin (H\&E) stained histopathology images. Moreover, the FCN method was applied for semantic segmentation of TCGA~\cite{gutman2013cancer} breast data set~\cite{amgad2019structured}, which is also used in this thesis. However, despite its popularity, the conventional FCN model has limitations such as loss of localization and the inability to process potentially useful global context information due to a series of down-sampling and a high sampling rate.

\subsection{Encoder-decoder networks}
A popular group of deep learning models for semantic image segmentation that aims to solve the aforementioned issues of FCNs is based on the convolutional encoder-decoder architecture~\cite{noh2015learning}. Their model consists of two parts, an encoder consisting of convolutional layers and a deconvolution network that consists of deconvolution and unpooling layers that take the feature vector as input and generate a map of pixel-wise class probabilities. Example for such a convolutional encoder-decoder architecture for image segmentation is SegNet~\cite{badrinarayanan2017segnet}. The SegNet's encoder network has 13 convolutional layers with corresponding layers in the decoder. The final decoder output is fed to a multi-class soft-max classifier to produce class probabilities for each pixel independently. The main feature of SegNet is that the decoder uses pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling. This allows it to achieve high scores for road scene understanding problems~\cite{badrinarayanan2017segnet}, COVID-19 lung computed tomography image segmentation~\cite{saood2021covid}, liver tumor segmentation in computed tomography scans~\cite{almotairi2020liver} and colon cancer histopathological images analysis~\cite{hamida2021deep}. There are several encoder-decoder models initially developed for biomedical image segmentation. Ronneberger et al.~\cite{10.1007/978-3-319-24574-4_28} proposed the U-Net model for segmenting biological microscopy images that can train with few annotated images effectively. U-Net has an FCN-like down-sampling part that extracts features with 3$\times$3 convolutions and an up-sampling part. Feature maps from the encoder are copied to the corresponding decoder part of the network to avoid losing pattern information. Besides the segmentation of neuronal structures in electron microscopic recordings demonstrated in the original paper~\cite{10.1007/978-3-319-24574-4_28}, U-Net was applied for numerous further tasks such as nuclei segmentation in histology images~\cite{lagree2021review, zeng2019ric}, segmenting individual colon glands in histopathology images~\cite{pinckaers2019neural}, epidermal tissue segmentation in histopathological images of skin biopsies~\cite{oskal2019u} and cell segmentation on histopathology triple-negative breast cancer patients dataset~\cite{bagdigen2020cell}. A further example of an encoder-decoder model for semantic segmentation of histopathology images is HookNet~\cite{van2021hooknet}. The architecture consists of two encoder-decoder branches to extract contextual and fine-grained detailed information and combine it (hook up) for the target segmentation. The model showed improvement compared with single-resolution models and was applied to segment different histopathologies like breast cancer tissue sections~\cite{van2021hooknet}, lung squamous cell carcinoma~\cite{van2021hooknet}, invasive melanoma tumor~\cite{shahdeep} and cervical cancer~\cite{meng2021cervical} slides.

Another widely used group of deep learning models for semantic segmentation are the atrous (or dilated) convolutional models that include the DeepLab family~\cite{chen2017deeplab, chen2017rethinking}. The use of atrous convolutions addresses the decreasing resolution caused by max-pooling and striding and Atrous Spatial Pyramid Pooling analyzes an incoming convolutional feature layer with filters at multiple sampling rates allowing to capture objects and image context at multiple scales to robustly segment objects at multiple scales. DeepLabv3+~\cite{chen2018encoder} uses encoder-decoder architecture including atrous separable convolution, composed of a depthwise convolution (spatial convolution for each channel of the input) and pointwise convolution (1$\times$1 convolution with the depthwise convolution as input). Authors~\cite{chen2018encoder} demonstrated the effectiveness of DeppLabv3+ model with modified Xception backbone at recognition of visual object classes in realistic scenes, but it also found multiple applications such as skin lesion segmentation~\cite{azad2020attention}, segmentation of H\&E stained breast cancer~\cite{priego2020automatic} and colorectal carcinoma~\cite{xu2022spatial} histopathology images. Despite all the efforts, even this popular architecture has constraints in learning long-range dependency and spatial correlations due to the inductive bias of locality and weight sharing~\cite{xie2021cotr} that may result in sub-optimal segmentation of complex structures. 

\subsection{Generative adversarial networks (GANs)}
GANs~\cite{goodfellow2014generative} have been applied to a wide range of computer vision tasks, and have been adopted for image segmentation too. The general architecture of GANs consists of the discriminator and the generator. The generator learns the training data distribution and produces similar data, while the discriminator discriminates between real data and simulated data. Hence the task of the generator is to learn to generate the best images to fool the discriminator. There are many extended models such as conditional GAN (cGAN)~\cite{mirza2014conditional} where the additional information is added to both the generator and the discriminator as a condition. This architecture was used for semantic segmentation of brain tumor in magnetic resonance imaging~\cite{rezaei2017conditional} and nuclei segmentation in histopathology images~\cite{mahmood2019deep}. Further extended version of cGAN, pix2pix~\cite{isola2017image} was developed for conversion between different types of images but also found use cases in medical setting such as cell image segmentation on the fluorescence liver images~\cite{Tsuda_2019_CVPR_Workshops} and retinal blood vessel segmentation~\cite{popescu2021retinal}. A further GAN extension originally developed for image transformation between two domains but also applicable for segmentation is CycleGAN~\cite{zhu2017unpaired}. The architecture has two mirror-symmetric GANs to form a ring network to find the mapping between domains. For instance, CycleGAN was applied to kidney tissue ~\cite{gadermayr2019generative} segmentation. Some GAN-based models were specifically developed for semantic segmentation in the medical domain, such as Domain Adaptation and Segmentation GAN (DASGAN)~\cite{kapil2019dasgan} that performs image-to-image translation and semantic tumor epithelium segmentation. It has an extended CycleGAN architecture with discriminator networks adjusted to predict pixel-wise class probability maps on top of predicting the correct source of an image. As a further example the proposed architecture consisting of pyramid of GAN structures~\cite{li2022high}, each responsible for generating and segmenting images at a different scale, was applied to segment prostate histopathology images.

\subsection{Recurrent neural networks (RNNs)}
RNNs~\cite{rumelhart1986learning} have also proven to be useful in modeling the short/long-term dependencies among pixels to generate segmentation maps. Pixels can be linked together and processed sequentially to model global contexts and improve semantic segmentation. ReSeg~\cite{visin2016reseg} is an RNN-based model for semantic segmentation. Each layer is composed of four RNNs that go through the image horizontally and vertically in both directions to provide relevant global information, while convolutional layers extract local features that are then followed by up-sampling layers to recover the predictions at original image resolution. Another important development is a pixel-level segmentation of scene images using a long-short-term-memory (LSTM) network~\cite{byeon2015scene}. Segmentation is then carried out by 2D LSTM networks, allowing texture and spatial model parameters to be learned within a single model. But despite all further developments that showcase the potential even for histopathology image segmentation: RACE-net~\cite{chakravarty2018race} applied for segmentation of the cell nuclei in H\&E stained breast cancer slides, Her2Net~\cite{saha2018her2net} segmenting cell membranes and nuclei from human epidermal growth factor receptor-2 (HER2)-stained breast cancer images, etc., 
an important limitation of RNNs is that, due to their sequential nature, they are comparably slower, since this sequential calculation cannot be easily parallelized. 

\subsection{Transformers}
The Transformer in  Natural Language Processing is an architecture that aims to solve sequence-to-sequence problems based on encoder-decoder architecture. These models rely on self-attention mechanisms and capture long-range dependencies among tokens (words) in a sentence without using RNNs or convolution. Transformers have also emerged into image semantic segmentation. Recent studies have shown that the Transformers can achieve superior performance than CNN-based approaches in various semantic segmentation applications~\cite{nguyen2022evaluating}. The state-of-the-art Transformer-based semantic segmentation methods can be often applied either as convolution-free models or/and as CNN-Transformer hybrid models. Swin-Transformer~\cite{liu2021swin} for instance is a pure hierarchical Transformer that can serve as a  backbone for various computer vision tasks including semantic segmentation. To tokenize the image, it brakes the image into windows that further consist of patches. It constructs a hierarchical representation of an image by starting from small-sized patches and gradually merging neighboring patches into deeper Transformer layers. Swin-Transformer or its slightly modified successors found its application in the medical domain as well, often as a backbone, for example for colon cancer segmentation in H\&E stained histopathology images~\cite{qian2022transformer} or gland segmentation~\cite{lin2022ds}. A further popular fully transformer-based model for semantic segmentation is Segmenter~\cite{strudel2021segmenter}. The encoder consists of Multi-head Self Attention and Multi-Layer Perceptron (MLP) blocks, as well as two-layer norms and residual connections after each block and a linear decoder that bilinearly up-samples the sequence into a 2D segmentation mask. While performing well on scene segmentation~\cite{strudel2021segmenter}, is not particularly used in the medical domain. In the field of medical image segmentation, TransUNet~\cite{chen2021transunet} was the first attempt to establish self-attention mechanisms by combining transformer with U-Net and proved that transformers can be used as powerful encoders for medical image segmentation. A novel positional-encoding-free Transformer SegFormer~\cite{https://doi.org/10.48550/arxiv.2105.15203} set new state-of-the-art in terms of efficiency and accuracy in publicly available semantic segmentation datasets and applied for instance in gland and nuclei segmentation~\cite{lin2022ds}. This architecture remains promising also for semantic segmentation in medical applications due to positional-encoding-free encoder and lightweight MLP decoder.

\section{Survival analysis}
\subsection{TILs score as prognostic value}
Tumor-Infiltrating Lymphocytes (TILs) have strong prognostic and predictive value in breast cancer~\cite{kos2020pitfalls, amgad2022mutils}. Amgad, M. et al.~\cite{amgad2022mutils} assessed three variants of the TILs score:
\begin{enumerate}
    \item Number of TILs / Stromal area 
    \item Number of TILs / Number of cells in stroma
    \item Number of TILs / Total Number of cells 
\end{enumerate}
The results conducted on the BCSS and NuCLS breast carcinoma datasets~\cite{amgad2019structured, amgad2021nucls} showed the most prognostic TILs score to be the number of TILs divided by the total number of cells within the stromal region.
A further breast cancer study~\cite{le2020utilizing} focused on the spatial distribution of TILs within tumor, by analyzing the proportion of pixels in the image that were predicted as containing tumor as well as lymphocytes (number of pixels predicted as lymphocyte and tumor divided by the number of pixels predicted as tumor).
Bai, et al.~\cite{bai2021open} also found associations of clinical outcomes in breast cancer with TILs scores based on
of number of TILs divided by the number of TILs and tumor cells detected.

The stromal TILs (sTILs) have been shown to have prognostic value in HER2+ breast cancer and TNBC~\cite{kos2020pitfalls}. 
Specifically for the TCGA-BRCA dataset, Thagaard, J. et al.~\cite{thagaard2021automated} tried to mimic the approach of the pathologist and therefore defined tumor-associated stroma. Tumor-associated stroma includes a margin of 250\textmu m from the border of the tumor into the surrounding stroma. The sTIL density was calculated as the number of TILs within the tumor-associated stroma per mm$^2$. The patient cohort was then stratified into two groups: high and low sTIL density by using maximally selected rank statistics for cutpoint selection. As a result sTIL density stratified the patients significantly into two distinct prognostic groups.  For continuous variables, the sTIL density was divided by 300 and higher sTILs scores were associated with significantly prolonged overall survival (OS). For the TCGA-BRCA dataset, a further TIL score was found significant as the overlapping area between lymphocyte-dense regions and stromal regions divided by the size of the stromal regions.~\cite{sun2021computational}  Whereas a further study, that focused on TNBC cases of TCGA, did not observe any differences in OS neither while using a continuous variable of manually annotated TILs (scored by a pathologist and partitioned into eight different groups, e.g. < 1\%, 10-20\%, etc.) nor after applying the log-rank test~\cite{craven2021cibersort}.
On the other hand, Fassler, D. J., et al.~\cite{fassler2022spatial} confirmed correlation of intratumoral TIL infiltration with increased OS in breast cancer in the TCGA BRCA cohort. TIL infiltrate percentage was calculated as the number of predicted patches that were classified as positive for tumor and lymphocyte divided by total number of cancer patches.
Another used definition of sTILs was the percentage of tumor stroma area containing a lymphocytic infiltrate without direct contact with tumor cells~\cite{meng2018distribution}.
Hence, there is no canonic method for the automatic determination of TILs score based on the H\&E breast cancer tissue samples.

Furthermore, studies found a three-scale grading system for reporting TILs status to be applicable, instead of continuous or binary grouped TILs density~\cite{kotoula2016tumors}. More advanced TILs-based features such as the Ball-Hall Index of spatially connected TILs regions (clusters) also showed association with survival, particularly within the BRCA dataset of TCGA~\cite{saltz2018spatial}. 
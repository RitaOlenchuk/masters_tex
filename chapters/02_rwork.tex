\chapter{Related work}

\section{Deep learning-based semantic segmentation}
The goal of semantic segmentation is to assign each image pixel
to a category label corresponding to the underlying object.
Due to the success of deep learning models in a wide range of vision applications,
various deep learning-based algorithms have been developed and
published in the literature~\cite{minaee2021image}.
One of the most prominent deep learning architectures used by the computer vision
community include fully convolutional networks (FCNs)~\cite{long2015fully},
encoder-decoders~\cite{noh2015learning}, generative adversarial networks
(GANs)~\cite{goodfellow2014generative} and recurrent neural networks (RNNs)~\cite{rumelhart1986learning}.
As Shephard, Adam et al. discuss~\cite{shephard2022tiager} like tissue segmentation, TILs detection
can be viewed as a semantic segmentation problem, since detection bounding boxes can be transformed
into pseudo-segmentation masks. The focus of the following chapters is to superficially introduce
the existing deep learning-based approaches for the histopathological tasks, that can be adapted or
extended for tissue and TILs segmentation of breast cancer WSIs.


\subsection{Fully convolutional networks (FCNs)}
FCNs~\cite{long2015fully} are among the most widely used architectures for computer vision
tasks and their general architecture consists of several learnable convolutions, pooling layers,
and a final 1$\times$1 convolution. Such models are used on segmentation problems
in histology domain such as colon glands segmentation~\cite{bentaieb2016topology},
as well as nuclei~\cite{natarajan2020segmentation} and TILs~\cite{amgad2019joint} segmentation for
breast cancer all performed on the Hematoxylin and Eosin (H\&E) stained histopathology images.
Moreover, the FCN method was applied for semantic segmentation of TCGA~\cite{gutman2013cancer}
breast data set~\cite{amgad2019structured}, which is also used in this thesis. However,
despite its popularity, the conventional FCN model has limitations such as loss of localization
and the inability to process potentially useful global context information due to a series of
down-sampling and a high sampling rate.

\subsection{Encoder-decoder networks}
A popular group of deep learning models for semantic image segmentation that aims to solve the
aforementioned issues of FCNs is based on the convolutional encoder-decoder architecture~\cite{noh2015learning}.
Their model consists of two parts, an encoder consisting of convolutional layers and a deconvolution
network that consists of deconvolution and unpooling layers that take the feature vector as input
and generate a map of pixel-wise class probabilities. An example of such a convolutional encoder-decoder
architecture for image segmentation is SegNet~\cite{badrinarayanan2017segnet}. The SegNet's encoder
network has 13 convolutional layers with corresponding layers in the decoder. The final decoder output
is fed to a multi-class soft-max classifier to produce class probabilities for each pixel independently.
The main feature of SegNet is that the decoder uses pooling indices computed in the max-pooling step
of the corresponding encoder to perform non-linear upsampling. This architecture also find a use in
histopathology, e.g. colon cancer analysis~\cite{hamida2021deep}. There are several encoder-decoder models
initially developed for biomedical image segmentation. Ronneberger et al.~\cite{10.1007/978-3-319-24574-4_28}
proposed the U-Net model for segmenting biological microscopy images that can train with few annotated
images effectively. U-Net has an FCN-like down-sampling part that extracts features with 3$\times$3
convolutions and an up-sampling part. Feature maps from the encoder are copied to the corresponding
decoder part of the network to avoid losing pattern information. Besides the segmentation of neuronal
structures in electron microscopic recordings demonstrated in the original paper~\cite{10.1007/978-3-319-24574-4_28},
U-Net was applied for numerous histopathology tasks such as nuclei segmentation~\cite{lagree2021review, zeng2019ric},
individual colon glands segmentation~\cite{pinckaers2019neural}, epidermal tissue segmentation of skin biopsies~\cite{oskal2019u}
and cell segmentation on triple-negative breast cancer patients dataset~\cite{bagdigen2020cell}.
A further development of an encoder-decoder model for semantic segmentation of histopathology images
is HookNet~\cite{van2021hooknet}. The architecture consists of two encoder-decoder branches to extract
contextual and fine-grained detailed information and combine it (hook up) for the target segmentation.
The model showed improvement compared with single-resolution models and was applied to segment
breast cancer tissue sections~\cite{van2021hooknet}.

Another widely used group of deep learning models for semantic segmentation are the atrous (or dilated)
convolutional models that include the DeepLab family~\cite{chen2017deeplab, chen2017rethinking}.
The use of atrous convolutions addresses the decreasing resolution caused by max-pooling and striding and
Atrous Spatial Pyramid Pooling analyzes an incoming convolutional feature layer with filters at multiple
sampling rates allowing to capture objects and image contexts at multiple scales to robustly segment objects
at multiple scales. DeepLabv3+~\cite{chen2018encoder} uses encoder-decoder architecture including atrous
separable convolution, composed of a depthwise convolution (spatial convolution for each channel of the
input) and pointwise convolution (1$\times$1 convolution with the depthwise convolution as input).
Authors~\cite{chen2018encoder} demonstrated the effectiveness of DeepLabv3+ model on
segmentation of H\&E stained breast cancer~\cite{priego2020automatic}. 
Despite all the efforts, even this popular architecture has constraints in learning long-range
dependency and spatial correlations due to the inductive bias of locality and weight
sharing~\cite{xie2021cotr} that may result in the sub-optimal segmentation of complex structures. 

\subsection{Recurrent neural networks (RNNs)}
RNNs~\cite{rumelhart1986learning} have proven to be useful in modeling the short/long-term dependencies
among pixels to generate segmentation maps. Pixels can be linked together and processed sequentially to
model global contexts and improve semantic segmentation. ReSeg~\cite{visin2016reseg} is an RNN-based
model for semantic segmentation. Each layer is composed of four RNNs that go through the image
horizontally and vertically in both directions to provide relevant global information,
while convolutional layers extract local features that are then followed by up-sampling layers
to recover the predictions at original image resolution. But despite all further developments that showcase the potential for
histopathology image segmentation: RACE-net~\cite{chakravarty2018race} applied for segmentation of the
cell nuclei in H\&E stained breast cancer slides, Her2Net~\cite{saha2018her2net} segmenting cell membranes
and nuclei from human epidermal growth factor receptor-2 (HER2)-stained breast cancer images, etc., 
an important limitation of RNNs is that, due to their sequential nature, they are comparably slower,
since this sequential calculation cannot be easily parallelized. 

\subsection{Transformers}
The Transformer in  Natural Language Processing is an architecture that aims to solve
sequence-to-sequence problems.
These models rely on self-attention mechanisms and capture long-range dependencies among tokens
(words) in a sentence without using RNNs or convolution. Transformers have also emerged in image
semantic segmentation. Recent studies have shown that the Transformers can achieve superior performance
than CNN-based approaches in various semantic segmentation applications~\cite{nguyen2022evaluating}.
The state-of-the-art Transformer-based semantic segmentation methods can be often applied either as
convolution-free models or/and as CNN-Transformer hybrid models. Swin-Transformer~\cite{liu2021swin}
for instance is a pure hierarchical Transformer that can serve as a  backbone for various computer
vision tasks including semantic segmentation. To tokenize the image, it brakes the image into windows
that further consist of patches. It constructs a hierarchical representation of an image by starting
from small-sized patches and gradually merging neighboring patches into deeper Transformer layers.
Swin-Transformer or its slightly modified successors found its application in the medical domain,
often as a backbone, for example for colon cancer segmentation in H\&E stained histopathology
images~\cite{qian2022transformer} or gland segmentation~\cite{lin2022ds}. A further popular fully
transformer-based model for semantic segmentation is Segmenter~\cite{strudel2021segmenter}.
The encoder consists of Multi-head Self Attention and Multi-Layer Perceptron (MLP) blocks, as well
as two-layer norms and residual connections after each block and a linear decoder that bilinearly
up-samples the sequence into a 2D segmentation mask. While performing well on scene
segmentation~\cite{strudel2021segmenter}, is not particularly used in the medical domain.
In the field of medical image segmentation, TransUNet~\cite{chen2021transunet} was the first attempt
to establish self-attention mechanisms by combining transformer with U-Net and proved that
transformers can be used as powerful encoders for medical image segmentation.
A novel positional-encoding-free Transformer SegFormer~\cite{xie2021segformer}
set new state-of-the-art in terms of efficiency and accuracy in publicly available semantic segmentation
datasets and applied for gland and nuclei segmentation~\cite{lin2022ds}.
This architecture remains promising also for semantic segmentation in medical
applications due to the positional-encoding-free encoder and lightweight MLP decoder.

\section{TILs as prognostic biomarker}
The overall survival (OS) is the primary endpoint for prognostic analysis in this thesis,
the survival methods are well established and include the Kaplanâ€“Meier method~\cite{kaplan1958nonparametric} to estimate OS
and Cox proportional hazard models~\cite{https://doi.org/10.1111/j.2517-6161.1972.tb00899.x} to quantify the hazard ratio (HR) for the effects of biomarker
groups. The following chapter focuses on conducted research for the development of TILs scores as a
prognostic biomarker for survival analysis in breast cancer based solely in histological slides.

Amgad, M. et al.~\cite{kos2020pitfalls, amgad2022mutils}. assessed three variants of the TILs score:
\begin{enumerate}
    \itemsep0em 
    \item Number of TILs / Stromal area 
    \item Number of TILs / Number of cells in stroma
    \item Number of TILs / Total Number of cells 
\end{enumerate}
The results performed on the BCSS and NuCLS breast carcinoma datasets~\cite{amgad2019structured, amgad2021nucls}
(the source datasets for TCGA part of TiGER dataset) showed the most prognostic TILs score to be the number of TILs
divided by the total number of cells within the stromal region.
A further breast cancer study~\cite{le2020utilizing} showed that the binarized tumor TILs infiltration fraction is
predictive of survival, by analyzing the proportion of pixels in the image that were predicted as containing
tumor as well as lymphocytes (number of pixels predicted as lymphocyte and tumor divided by the number of pixels
predicted as tumor).
Bai, et al.~\cite{bai2021open} also found associations of clinical outcomes in breast cancer with TILs scores based on
the number of TILs divided by the number of TILs and tumor cells detected.

The stromal TILs (sTILs) have been shown to have prognostic value in HER2+ breast cancer and TNBC~\cite{kos2020pitfalls}. 
sTIL density was found significantly prognostic for OS not only while applied on H\&E slides but IHC as well.~\cite{kapil2021breast}
Applied on the TCGA-BRCA mixed with non publicaly available dataset, Thagaard, J. et al.~\cite{thagaard2021automated} tried to mimic the approach of the pathologist and therefore defined tumor-associated stroma. Tumor-associated stroma includes a margin of 250\textmu m from the border of the tumor into the surrounding stroma. The sTIL density was calculated as the number of TILs within the tumor-associated stroma per mm$^2$. The patient cohort was then stratified into two groups: high and low sTIL density by using maximally selected rank statistics for cutpoint selection. As a result sTIL density stratified the patients significantly into two distinct prognostic groups.  For continuous variables, the sTIL density was divided by 300 and higher sTILs scores were associated with significantly prolonged overall survival. For the TCGA-BRCA dataset, a further TIL score was found significant as the overlapping area between lymphocyte-dense regions and stromal regions divided by the size of the stromal regions.~\cite{sun2021computational}  Whereas a study, that focused on TNBC cases of TCGA, did not observe any differences in OS neither while using a continuous variable of manually annotated TILs (scored by a pathologist and partitioned into eight different groups, e.g. < 1\%, 10-20\%, etc.) nor after applying the log-rank test~\cite{craven2021cibersort}.
On the other hand, Fassler, D. J., et al.~\cite{fassler2022spatial} confirmed correlation of intratumoral TIL infiltration with increased OS in breast cancer in the TCGA-BRCA cohort. TIL infiltrate percentage was calculated as the number of predicted patches that were classified as positive for tumor and lymphocyte divided by total number of cancer patches.
Another used definition of sTILs was the percentage of tumor stroma area containing a lymphocytic infiltrate without direct contact with tumor cells~\cite{meng2018distribution}.
Furthermore, studies found a three-scale grading system for reporting TILs status to be applicable, instead of continuous or binary grouped TILs densities~\cite{kotoula2016tumors}. More advanced TILs-based features such as the Ball-Hall Index of spatially connected TILs regions (clusters) also showed association with survival, particularly within the BRCA dataset of TCGA~\cite{saltz2018spatial}. 
Hence, there is no canonic method for the automatic determination of TILs score based on the H\&E breast cancer tissue samples but number of TILs per mm$^2$ of stromal area is used most frequently.
